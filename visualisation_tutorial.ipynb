{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VisDa8: Jupyter Notebooks. Interactive notebook tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of the tutorial:\n",
    "1. Introduction to Jupyter Notebooks.\n",
    "2. Basics of using Jupyter Notebooks (livecoding).\n",
    "3. Example of data analysis: Fetch and visualise weather data from Deutscher Wetterdienst (livecoding).\n",
    "4. Introduction to Observable Notebooks.\n",
    "<br><br>\n",
    "\n",
    "## Introduction.\n",
    "\n",
    "### What is a Jupyter Notebook?\n",
    "The [Jupyter Notebook](https://jupyter.org/) is an open-source web application that allows you to create and share documents that contain live code, equations, visualisations and narrative text. <br>\n",
    "Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualisation, machine learning, and much more. \n",
    "<br><br>\n",
    "\n",
    "### What software do I need to work with Jupyter Notebooks?\n",
    "To work with Jupyter Notebooks using the python programming language, you first need to install Anaconda. <br>\n",
    "Anaconda is an open source distribution for the programming languages Python and R, which aims to simplify package management and software deployment. <br>\n",
    "You can install Anaconda by following the instructions of the [website](https://docs.anaconda.com/anaconda/install/). <br>\n",
    "<br>\n",
    "After the basic installation of Anaconda, Jupyter Notebook should also be pre-installed. <br>\n",
    "Otherwise it can be installed according to the instructions on the [website](https://jupyter.org/install). <br>\n",
    "<br>\n",
    "If you are a more advanced user with Python already installed and prefer to manage your packages manually, you can just use [pip](https://pypi.org/project/jupyter/). <br>\n",
    "<br>\n",
    "For this tutorial we will provide you a browser version, so you don't have to install anything.\n",
    "<br><br>\n",
    "\n",
    "### Basics of working with a Jupyter Notebook.\n",
    "Code parts or text contents are organised in sequential cells. This enables separate execution of each one. <br>\n",
    "This allows you to display intermediate results directly or to optimise individual sections of code without having to execute the entire source code each time. <br>\n",
    "You can also insert images or tables into the document. Double click on this cell to see how it works and then press `Shift + Enter` to run this cell again! <br>\n",
    "\n",
    "<img src=\"https://www.dlr.de/content/de/bilder/institute/datenwissenschaften/dw-institutsgebaeude.jpg?__blob=normal&v=10__ifc1920w\" \n",
    "alt=\"DLR Institut fÃ¼r Datenwissenschaften Jena\"\n",
    "style=\"width:800px;\">\n",
    "\n",
    "Before we start programming, here are a few **useful shortcuts** for using Jupyter notebooks: <br>\n",
    "\n",
    "`Shift + Enter` run the current cell, select below. <br>\n",
    "`Ctrl + Enter` run selected cells. <br>\n",
    "\n",
    "While in **command mode** (press `Esc` to activate): <br>\n",
    "\n",
    "`Enter` take you into **edit mode**. <br>\n",
    "`a` insert cell above. <br>\n",
    "`b` insert cell below. <br>\n",
    "`dd` delete selected cells. <br>\n",
    "`z` undo cell deletion. <br>\n",
    "`y` change the cell type to Code. <br>\n",
    "`m` change the cell type to Markdown (text). <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Features\n",
    "## Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bash commands inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> :warning: **if the bash command requires interaction, it will fail**: Be careful here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magic\n",
    "You can measure the time, autoreload packages or show matplotlib plots inline([magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html?highlight=time#))\n",
    "\n",
    "Time execution of a Python statement or expression\n",
    "\n",
    "```python\n",
    "%time fibRecursive(n)\n",
    "```\n",
    "autoreload reloads modules automatically before entering the execution of code\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "```\n",
    "\n",
    "To enable the inline backend for usage with the IPython Notebook\n",
    "```python\n",
    "%matplotlib inline\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive\n",
    "def fib_recursive(n):\n",
    "    if n<=0:\n",
    "        print(\"Incorrect input\")\n",
    "    # base case\n",
    "    elif n==1 or n==2:\n",
    "        return 1\n",
    "    # recursive case\n",
    "    else:\n",
    "        return fib_recursive(n-1)+fib_recursive(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative\n",
    "def fib_iterative(n):\n",
    "    a, b = 0, 1\n",
    "    for i in range(n):\n",
    "        # set a = b and b = a + b\n",
    "        a, b = b, a + b\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data from Deutscher Wetterdienst.\n",
    "To run a selected cell and then jump to the next one press `Ctrl + Enter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For safety reasons these cells are set to raw. The execution takes relatively long and the data is already provided as csv.\n",
    "To run it press `Y` while it is selected, to convert it back to raw press `r`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import needed libraries.\n",
    "# Pandas for managing data in dataframes.\n",
    "import pandas as pd\n",
    "\n",
    "# Plotly for visualisation.\n",
    "import plotly.express as px\n",
    "\n",
    "# Further imports.\n",
    "import numpy as np\n",
    "import io\n",
    "import zipfile\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# file holding all stations known\n",
    "STATIONS_PATH = \"stations_daily.csv\"\n",
    "RECENT_DAILY_WEATHER_DATA_PATH = \"recent_daily_weather_data.csv\"\n",
    "RECENT_DAILY_WEATHER_DATA_CLEANED_PATH = \"recent_daily_weather_data_cleaned.csv\"\n",
    "\n",
    "# holds all paths to the data at dwd\n",
    "DWD_DATA_URI = \"https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/{resolution}/{attribute}/recent/{filename}.zip\"\n",
    "DWD_STATIONS_DAILY_URI = \"https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/daily/kl/recent/KL_Tageswerte_Beschreibung_Stationen.txt\"\n",
    "DWD_STATIONS_HOURLY_URI = \"https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/air_temperature/recent/TU_Stundenwerte_Beschreibung_Stationen.txt\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This function gets an overview of the available weather stations.\n",
    "def fetch_station_descriptions(uri):\n",
    "    \"\"\"\n",
    "    Fetches the meta data for all stations\n",
    "    \"\"\"\n",
    "    response = requests.get(uri)\n",
    "    if not response.ok:\n",
    "        raise RuntimeError(f\"Failed to fetch station data from '{uri}'!\")\n",
    "    \n",
    "    content = response.text\n",
    "    content = content.strip()\n",
    "    content = content.replace(\"\\r\", \"\")\n",
    "    content = content.replace(\"\\n\\n\", \"\\n\")\n",
    "    \n",
    "    df = pd.read_csv(io.StringIO(content), sep=\"\\s{2,}\", skiprows=2, header=None)\n",
    "    df[[\"station_id\", \"date_start\", \"date_end\"]] = df[0].str.split(\" \", expand=True)\n",
    "    df[[\"geo_lon\", \"name\"]] = df[3].str.split(\" \", 1, expand=True)\n",
    "    df = df.rename(columns={\n",
    "        1: \"height\",\n",
    "        2: \"geo_lat\",\n",
    "    })\n",
    "    df[\"station_id\"] = df[\"station_id\"].astype(np.int)\n",
    "    df[\"date_start\"] = pd.to_datetime(df[\"date_start\"], format=\"%Y%m%d\")\n",
    "    df[\"date_end\"] = pd.to_datetime(df[\"date_end\"], format=\"%Y%m%d\")\n",
    "    return df[[\"station_id\", \"date_start\", \"date_end\", \"geo_lon\", \"geo_lat\", \"height\", \"name\"]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Get an overview of the available stations and save it to a csv-file.\n",
    "stations_daily = fetch_station_descriptions(uri=DWD_STATIONS_DAILY_URI)\n",
    "stations_daily.to_csv(\"stations_daily.csv\", index=None)\n",
    "stations_daily = stations_daily.set_index(\"station_id\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This function loads the data for a specific weather station id from the DWD-server.\n",
    "# It returns a pandas dataframe.\n",
    "def download_recent_daily_weather_data(station_id):\n",
    "    url = DWD_DATA_URI.format(resolution=\"daily\", attribute=\"kl\", filename=f\"tageswerte_KL_{station_id:05}_akt\")\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if not response.ok:\n",
    "        return None\n",
    "\n",
    "    # If the request is successful, we get a zip-file that contains the data.\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as datazip:\n",
    "        filename = [name for name in datazip.namelist() if name.startswith(\"produkt\")][0]\n",
    "        with datazip.open(filename) as data_buffer:\n",
    "            df = pd.read_csv(data_buffer, delimiter=\";\", skipinitialspace=True)\n",
    "            # Transform the datetime string to a datetime object.\n",
    "            df[\"MESS_DATUM\"] = pd.to_datetime(df[\"MESS_DATUM\"], format=\"%Y%m%d\")\n",
    "            # Only keep the relevant columns.\n",
    "            df = df[[\"STATIONS_ID\", \"MESS_DATUM\", \"TMK\", \"TNK\", \"TXK\", \"TGK\", \"RSK\", \"RSKF\", \"UPM\"]]\n",
    "            # Rename the columns.\n",
    "            df = df.rename(columns={\n",
    "                \"STATIONS_ID\": \"id\",\n",
    "                \"MESS_DATUM\": \"date\",\n",
    "                \"TMK\": \"mean_temperature\",\n",
    "                \"TNK\": \"min_temperature_200cm\",\n",
    "                \"TXK\": \"max_temperature_200cm\",\n",
    "                \"TGK\": \"min_temperature_005cm\",\n",
    "                \"RSK\": \"precipitation_amount\",\n",
    "                \"RSKF\": \"precipitation_type\",\n",
    "                \"UPM\": \"mean_relative_humidity\",\n",
    "            })\n",
    "            return df\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Our list of dataframes for each weather station.\n",
    "recent_daily_weather_data = []\n",
    "# Get the data for every weather station.\n",
    "for index, row in pd.read_csv(STATIONS_PATH).iterrows():\n",
    "    try:\n",
    "        # Try to download the weather data.\n",
    "        print(\"Loading... \", end=\"\\t\")\n",
    "        name = re.sub(r\"[^\\u00C0-\\u017Fa-zA-Z\\d:]+\",\"_\",row[\"name\"])\n",
    "        name = name[:-1] if name[-1] == \"_\" else name\n",
    "        print(f\" ...{name}... \", end=\"\\t\")\n",
    "        # Attach the current dataframe to the list of dataframes.\n",
    "        recent_daily_weather_data.append(download_recent_daily_weather_data(station_id=row[\"station_id\"]))\n",
    "    except:\n",
    "        print(\" ...failed\")\n",
    "    else:\n",
    "        print(\" ...done\")\n",
    "print(\"Everthing is loaded\")\n",
    "\n",
    "# Unite all datasets.\n",
    "joint_recent_daily_weather_data = pd.concat(recent_daily_weather_data, ignore_index=True)\n",
    "\n",
    "# Save the weather data to a csv-file.\n",
    "joint_recent_daily_weather_data.to_csv(RECENT_DAILY_WEATHER_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries.\n",
    "# Pandas for managing data in dataframes.\n",
    "import pandas as pd\n",
    "\n",
    "# Plotly for visualisation.\n",
    "import plotly.express as px\n",
    "\n",
    "# Further imports.\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File holding all of the weather data.\n",
    "RECENT_DAILY_WEATHER_DATA_PATH = \"recent_daily_weather_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the data into a pandas dataframe (The data are already read in if you run the code above).\n",
    "df_weather = pd.read_csv(RECENT_DAILY_WEATHER_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive data visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File holding all stations known.\n",
    "STATIONS_PATH = \"stations_daily.csv\"\n",
    "# File holding the cleaned data.\n",
    "RECENT_DAILY_WEATHER_DATA_CLEANED_PATH = \"recent_daily_weather_data_cleaned.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the informations about the stations and the cleaned data.\n",
    "df_stations = pd.read_csv(STATIONS_PATH, header=0, index_col=0)\n",
    "df_weather = pd.read_csv(RECENT_DAILY_WEATHER_DATA_CLEANED_PATH, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the available weather stations on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the weather data for a specific weather station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
